<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>Dependency Tree Collapse for N-Gram Generation :: Alex Day</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="description" content="Introduction   Throughout the past semester I have been working on my senior capstone project for my CS undergraduate. The project is to create Emoji summaries for sentences and one of the integral parts of this algorithm is separating a sentence into a sequence of n-grams that represent it. In the initial algorithm, I took a naive approach of generating every single combination of n-grams, summarizing them all, and then returning the summary with the highest result." />
<meta name="keywords" content="Coding, PhD, Clemson" />
<meta name="robots" content="noodp" />
<link rel="canonical" href="/posts/dependency-tree-collapse/" />




<link rel="stylesheet" href="/assets/style.css">

  <link rel="stylesheet" href="/assets/green.css">



<link rel="stylesheet" href="/style.css">


<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/img/apple-touch-icon-144-precomposed.png">

  <link rel="shortcut icon" href="/favicon.ico">



<meta name="twitter:card" content="summary" />

  <meta name="twitter:site" content="" />

<meta name="twitter:creator" content="" />


<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Dependency Tree Collapse for N-Gram Generation :: Alex Day">
<meta property="og:description" content="Splitting a sentence into n-gram chunks based on the dependency relations" />
<meta property="og:url" content="/posts/dependency-tree-collapse/" />
<meta property="og:site_name" content="Dependency Tree Collapse for N-Gram Generation" />

  
    <meta property="og:image" content="/favicon.ico">
  

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">


  <meta property="article:published_time" content="2019-11-06 00:00:00 &#43;0000 UTC" />











  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</head>
<body class="">


<div class="container center headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Alex Day
  </div>
</a>

    </div>
    <div class="menu-trigger">menu</div>
  </div>
  
    <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/posts">Posts</a></li>
        
      
        
          <li><a href="/papers">Papers</a></li>
        
      
        
          <li><a href="/talks">Talks</a></li>
        
      
      
    

    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/about">About</a></li>
      
    
      
        <li><a href="/posts">Posts</a></li>
      
    
      
        <li><a href="/papers">Papers</a></li>
      
    
      
        <li><a href="/talks">Talks</a></li>
      
    
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="/posts/dependency-tree-collapse/">Dependency Tree Collapse for N-Gram Generation</a></h1>
  <div class="post-meta">
      
    <span class="post-date">
      2019-11-06
    </span>
    
    
  </div>

  
  <span class="post-tags">
    
    #<a href="/tags/capstone_project/">Capstone_Project,</a>&nbsp;
    
    #<a href="/tags/nlp/">NLP</a>&nbsp;
    
  </span>
  

  

  <div class="post-content"><div>
        
<h2 id="headline-1">
Introduction
</h2>
<p>
Throughout the past semester I have been working on my senior capstone project
for my CS undergraduate. The project is to create Emoji summaries
for sentences and one of the integral parts of this algorithm is separating a
sentence into a sequence of n-grams that represent it. In the initial algorithm,
I took a naive approach of generating every single combination of n-grams,
summarizing them all, and then returning the summary with the highest result.
While this worked it did have some downsides. The main disadvantage of attacking
the problem in this way was some of the n-grams contained two big ideas from the
sentence and they were only getting translated to one Emoji. It was clear that
this was not ideal. The approach detailed within this post uses information
about the dependencies between words within the sentence in hopes that this will
produce an output that is more representative.
</p>
<h2 id="headline-2">
Dependency Trees
</h2>
<p>
Dependency trees are a way to map the dependencies of words within a sentence.
The example in figure 1 maps the dependencies within the sentence &#34;I finished my
homework just before the class started&#34;. Because the node containing &#34;I&#34; is a
child of the &#34;finished&#34; node there is a direct relation between the two words.
In this case &#34;I&#34; is the object that actually &#34;finished&#34; something. In this
dependency tree (and in the algorithm) the actual relations that link words
together are neither shown or used.
</p>
<p>

  <figure class="left" >
    <img src="/img/tree_collapse/syntax.png"  alt="A tree-like structure containing a sentence with the parts of speech of each word label as well as the dependencies shown by edges"   />
    
      <figcaption class="center" >Dependency tree for an example sentence</figcaption>
    
  </figure>


</p>
<h2 id="headline-3">
Rules for Collapse
</h2>
<p>
The primary assumption behind this algorithm is that some dependencies can be collapsed, or
simplified to produce larger n-grams that make up the sentence. As of right now the algorithm
only executes two rules but it is easy to imagine other rules that could be used. The rules
are as follows:
</p>
<ol>
<li>
<p>
If a node has only one child then the two nodes can be combined into one
</p>
</li>
<li>
<p>
If multiple leaves are on the same level and have the same parent then they can be combined into one node
</p>
<h3 id="headline-4">
Child Dependency
</h3>
</li>
</ol>
<p>

  <figure class="left" >
    <img src="/img/tree_collapse/child_step_one.png"  alt="The same tree from above except there is a direct node to node relation with no other children. These two nodes are n-gramed"   style="margin: auto"  />
    
      <figcaption class="center" >The same tree from above except there is a direct node to node relation with no other children. These two nodes are n-gramed</figcaption>
    
  </figure>



  <figure class="left" >
    <img src="/img/tree_collapse/child_step_two.png"  alt="The same tree as in the image above but the two n-gramed nodes have been collapsed and are now just one node"   style="margin: auto"  />
    
      <figcaption class="center" >The same tree as in the image above but the two n-gramed nodes have been collapsed and are now just one node</figcaption>
    
  </figure>


</p>
<h3 id="headline-5">
Neighbor dependency
</h3>
<p>

  <figure class="left" >
    <img src="/img/tree_collapse/neighbor_step_one.png"  alt="The same tree from above except there are nodes highlighted that are neighbors on the leaf level. These two nodes are n-gramed"   style="margin: auto"  />
    
      <figcaption class="center" >The same tree from above except there are nodes highlighted that are neighbors on the leaf level. These two nodes are n-gramed</figcaption>
    
  </figure>



  <figure class="left" >
    <img src="/img/tree_collapse/neighbor_step_two.png"  alt="The same tree as in the image above but the two n-gramed nodes have been collapsed and are now just one node"   style="margin: auto"  />
    
      <figcaption class="center" >The same tree as in the image above but the two n-gramed nodes have been collapsed and are now just one node</figcaption>
    
  </figure>


</p>
<h2 id="headline-6">
Results
</h2>
<p>
This algorithm is used directly in the sentence to Emoji algorithm, so it makes the most
sense to present results as relative to its&#39; application. Table 1 below shows the
results from the old exhaustive n-gram sequencing algorithm as compared to this
dependency relation informed algorithm.
</p>
<table>
<thead>
<tr>
<th>Sentence</th>
<th>Exhaustive</th>
<th>Dependency Tree</th>
</tr>
</thead>
<tbody>
<tr>
<td>The student drew a snowflake on the chalk board</td>
<td><code>The student drew</code> <code>a</code> <code>snowflake</code> <code>on</code> <code>the chalk board</code></td>
<td><code>The student</code> <code>drew</code> <code>a snowflake</code> <code>the chalk</code> <code>on board</code></td>
</tr>
<tr>
<td>I finished the homework just before class started</td>
<td><code>I</code> <code>finished the homework just before class started</code></td>
<td><code>I</code> <code>finished</code> <code>the homework</code> <code>just before class</code> <code>started</code></td>
</tr>
<tr>
<td>Can you calculate the number of giraffes that have ever existed?</td>
<td><code>can</code> <code>you calculate the number of giraffe that have ever existed</code></td>
<td><code>can you</code> <code>calculate</code> <code>number</code> <code>that have ever</code> <code>of giraffes existed</code></td>
</tr>
</tbody>
</table>
<p>
It is relatively clear that the tree collapse n-gram generation gives a more comprehensive
n-gram sequence for the sentence. However, this may be more of a reflection of the naive-ness
of our initial algorithm. The exhaustive algorithm relies entirely on the dataset that is
used for the output Emoji. The lacklustre dataset is something that will be improved shortly.
</p>
<h2 id="headline-7">
Implementation
</h2>
<p>
Below, in figure 5, is the algorithm implemented in Python 3 with spaCy and
NLTK. The general flow of the algorithm is that it performs the collapses
detailed above and returns a list of lists. Each list within the result is
an n-gram split into its&#39; constituent words. It is implemented as such so
the word can also contain the initial location of the word within the input
so it can later be sorted. Sorting is trivial and it (along with the rest of the code) is contained within
<a href="https://github.com/AlexanderDavid/Sentence-to-Emoji-Translation/blob/master/JupyterNotebooks/PartOfSpeech.ipynb">this Juypter notebook</a> within the <a href="https://github.com/AlexanderDavid/Sentence-to-Emoji-Translation/">algorithms repo</a>.
</p>
<div class="src src-python">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">pos_n_gram_sequence</span>(node, n_grams<span style="color:#f92672">=</span>None):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    Turn the sentence given into an n-gram sequence informed
</span><span style="color:#e6db74">    by part of speech tagging
</span><span style="color:#e6db74">
</span><span style="color:#e6db74">    Args:
</span><span style="color:#e6db74">        node(Token or str): Root token for the sentence or the
</span><span style="color:#e6db74">                    sentence as a string if first run through
</span><span style="color:#e6db74">        n_grams(List, Optional): List of n-grams for recursion
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    <span style="color:#75715e"># Check if the n_grams list is none. If so it is the</span>
    <span style="color:#75715e"># first run through of the function then set up the</span>
    <span style="color:#75715e"># list and the sentence as an spaCy NLP root node.</span>
    <span style="color:#75715e"># We do it with none because python gets</span>
    <span style="color:#75715e"># slightly weird if you do this with an empty list</span>
    <span style="color:#66d9ef">if</span> n_grams <span style="color:#f92672">is</span> None:
        n_grams <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">if</span> type(node) <span style="color:#f92672">is</span> str:
        node <span style="color:#f92672">=</span> list(nlp(node)<span style="color:#f92672">.</span>sents)[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>root

    <span style="color:#75715e"># Rule 1.</span>
    <span style="color:#75715e"># While the current node only has one child append the</span>
    <span style="color:#75715e"># data from the current node to a backlog list and then</span>
    <span style="color:#75715e"># loop down to the next node, checking it&#39;s child count</span>
    <span style="color:#75715e"># so on and so forth</span>
    current_node <span style="color:#f92672">=</span> node
    parent_child_data <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">while</span> current_node<span style="color:#f92672">.</span>n_lefts <span style="color:#f92672">+</span> current_node<span style="color:#f92672">.</span>n_rights <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
        <span style="color:#75715e"># Appending both the node&#39;s token and its&#39; position in the</span>
        <span style="color:#75715e"># sentence so we can sort later</span>
        parent_child_data<span style="color:#f92672">.</span>append((current_node<span style="color:#f92672">.</span>orth_, current_node<span style="color:#f92672">.</span>i))
        <span style="color:#75715e"># Set the current node to the only child of the current node</span>
        current_node <span style="color:#f92672">=</span> list(current_node<span style="color:#f92672">.</span>children)[<span style="color:#ae81ff">0</span>]

    <span style="color:#75715e"># Add the current node&#39;s data to the parent-child dependency</span>
    <span style="color:#75715e"># list so we can just add this to the result later</span>
    parent_child_data<span style="color:#f92672">.</span>append((current_node<span style="color:#f92672">.</span>orth_, current_node<span style="color:#f92672">.</span>i))
    n_grams<span style="color:#f92672">.</span>append(parent_child_data)

    <span style="color:#75715e"># Rule 2. will only work if the current node has more than one</span>
    <span style="color:#75715e"># child. If it has less than that then we already appended</span>
    <span style="color:#75715e"># everything relevant to the list</span>
    <span style="color:#66d9ef">if</span> <span style="color:#f92672">not</span> current_node<span style="color:#f92672">.</span>n_lefts <span style="color:#f92672">+</span> current_node<span style="color:#f92672">.</span>n_rights <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span>:
        <span style="color:#66d9ef">return</span>

    <span style="color:#75715e"># Get the children of the current node that have children</span>
    children_with_children <span style="color:#f92672">=</span> [child <span style="color:#66d9ef">for</span> child <span style="color:#f92672">in</span> current_node<span style="color:#f92672">.</span>children
                            <span style="color:#66d9ef">if</span> len(list(child<span style="color:#f92672">.</span>children)) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>]

    <span style="color:#75715e"># Leaves are nodes that don&#39;t have children. Any children</span>
    <span style="color:#75715e"># of the current node that are not in the</span>
    <span style="color:#75715e"># children_with_children list are leaves and should be</span>
    <span style="color:#75715e"># collapsed</span>
    leafs <span style="color:#f92672">=</span> [(child<span style="color:#f92672">.</span>orth_, child<span style="color:#f92672">.</span>i)
            <span style="color:#66d9ef">for</span> child <span style="color:#f92672">in</span> current_node<span style="color:#f92672">.</span>children
            <span style="color:#66d9ef">if</span> child <span style="color:#f92672">not</span> <span style="color:#f92672">in</span> children_with_children]

    <span style="color:#75715e"># Append the leafs to the n_grams</span>
    n_grams<span style="color:#f92672">.</span>append(leafs)

    <span style="color:#75715e"># Recurse through all the non-leaf children</span>
    <span style="color:#66d9ef">for</span> child <span style="color:#f92672">in</span> children_with_children:
        pos_n_gram_sequence(child, n_grams)

    <span style="color:#66d9ef">return</span> n_grams</code></pre></div>
</div>
<h2 id="headline-8">
Future Work
</h2>
<p>
The one main future iteration for this algorithm involves generating more potential n-gram
sequences. The current implementation only collapses the tree once to produce one n-gram
sequence but it wouldn&#39;t be that hard to further collapse the tree to produce more. This
further collapse could prove to improve the summary for longer sentences and could be combined
with other n-gram sequence scoring techniques.
</p>
<h2 id="headline-9">
Related Reading and Works
</h2>
<ul>
<li>
<p>
<a href="http://tomato.banatao.berkeley.edu:8080/parser/parser.html">Online Dependency Tree Parser</a>
</p>
</li>
<li>
<p>
<a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">Part of Speech Tagging on Wikipedia</a>
</p>
</li>
<li>
<p>
<a href="https://spacy.io/usage/linguistic-features#pos-tagging">Part of Speech Tagging in spaCy</a>
</p>
</li>
<li>
<p>
<a href="https://github.com/AlexanderDavid/Sentence-to-Emoji-Translation/blob/df18176149970e0143d38ee2aacfc658e0b4f56c/EmojiTranslation/Translators.py#L381">Part of Speech Tagging Translator Code (as of 11/11/19)</a>
</p>
</li>
</ul>

      </div></div>
  
  <div class="pagination">
    <div class="pagination__title">
      <span
        class="pagination__title-h">Read other posts</span>
      <hr />
    </div>
    <div class="pagination__buttons">
      
      
      <span class="button next">
        <a href="/posts/naive-emoji-summarization/">
          <span class="button__text">Naive Sentence to Emoji Translation</span>
          <span class="button__icon">→</span>
        </a>
      </span>
      
    </div>
  </div>
  

  

</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright copyright--user">
        <span>© 2020 Alex Day</span>
    
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
  </div>
</footer>

<script src="/assets/main.js"></script>
<script src="/assets/prism.js"></script>





  
</div>

</body>
</html>
